---
layout: about
title: About
permalink: /
# subtitle: Soon to graduate PhD student at the <a href="https://www.bristol.ac.uk">University of Bristol</a>

profile:
  align: right
  image: IMG_6576.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>alexander@quessy.io</p>

news: False # includes a list of news items
latest_posts: False  # includes a list of the newest posts
selected_papers: False # includes a list of papers marked as "selected={true}"
# social: True  # includes social icons at the bottom of the page
---

<div class="blog-banner">
  <p>📝 Check out my blog -> <a href="https://aos55.github.io/deltaq/" target="_blank">∇Q</a>!</p>
</div>

I'm a machine learning researcher specializing in Reinforcement Learning (RL) and robotics, with a focus on developing AI systems that can operate safely in real-world environments. I recently completed my PhD at the [Bristol Flight Lab](https://bristolflightlab.com/), advised by [Thomas Richardson](https://research-information.bris.ac.uk/en/persons/tom-s-richardson) and [Sebastian East](https://sebastian-east.github.io), where I developed autonomous landing systems for aircraft and created scalable simulation frameworks for training RL agents.

My research addresses core challenges in autonomous systems: learning from sparse rewards, generalizing across environments, and maintaining safety in critical applications. I've built systems that combine deep learning with control theory, deployed models on real aircraft, and created open-source tools used by the robotics community.
<!-- Currently working as a Research Scientist at DeepWell, I'm developing advanced ML models for financial applications while continuing to explore applications of RL to robotics and autonomous systems. I'm particularly interested in roles that bridge academic research with practical deployment of intelligent systems. -->

**Background:** PhD and MEng in Aerospace Engineering from the University of Bristol. Also, a commercial pilot and flight instructor, bringing real-world understanding of safety-critical systems to my research.


<!-- I design algorithms to enable autonomous decision-making under uncertainty, particularly in safety-critical domains. My research combines ideas from reinforcement learning (RL) and control theory to tackle fundamental challenges in autonomous systems, especially problems involving sparse rewards and generalization. I completed my PhD at the [Bristol Flight Lab](https://bristolflightlab.com/), where I was advised by [Thomas Richardson](https://research-information.bris.ac.uk/en/persons/tom-s-richardson) and [Sebastian East](https://sebastian-east.github.io), where I developed novel approaches for training autonomous agents that can operate reliably in complex, real-world environments.

Specifically, my work has explored (1) how to develop autonomous agents that can safely navigate and land fixed-wing aircraft in emergency scenarios, (2) how to leverage unsupervised learning techniques to learn generalizable policies in environments with sparse rewards, and (3) how to automatically generate increasingly complex training environments through learned curricula. Currently, I'm especially interested in developing robust generalizable algorithms for real-world systems in safety-critical applications.

**Bio:** I hold both a PhD and MEng in Aerospace Engineering from the University of Bristol. Beyond my academic work, I'm a UK CAA certified commercial pilot and flying instructor, specializing in multi-engine and aerobatic instruction. -->
